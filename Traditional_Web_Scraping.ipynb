{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traditional Web-Scraping",
      "provenance": [],
      "authorship_tag": "ABX9TyM++byTqakrhEbRBBHEWb3p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neelmehta00/RealEstateMoguls/blob/master/Traditional_Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIWKL_D3tuMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "def rec(text, i):\n",
        "    locdate = text.find(\"Date:\")\n",
        "    loccomma = text.find(\",\",locdate)\n",
        "    locprice = text.find(\"Price:\")\n",
        "    loccommap = text.find(\"(\",locprice)\n",
        "    price = (text[locprice+8: loccommap-1])\n",
        "    finaldate = (text[locdate+6:loccomma])\n",
        "    if(locdate == -1):\n",
        "        return\n",
        "    finalprice = \"\"\n",
        "    for ch in price:\n",
        "        if ch != \",\":\n",
        "            finalprice = finalprice + ch\n",
        "    pricehist = [finaldate, finalprice]\n",
        "    newtext = text[loccommap:]\n",
        "    final[i].append(pricehist)\n",
        "    rec(newtext, i)\n",
        "def basics(houselink, i):\n",
        "\n",
        "    with requests.Session() as s:\n",
        "        url = houselink\n",
        "        r = s.get(url, headers=req_headers)\n",
        "    soup = BeautifulSoup(r.content, 'lxml')\n",
        "    try:\n",
        "        price = soup.find(\"span\", {\"class\": \"ds-value\"})\n",
        "    except:\n",
        "        price = \"0\"\n",
        "    try:\n",
        "        bed = soup.findAll(\"span\", {\"class\": \"ds-bed-bath-living-area\"}) #bed bath and sqft in order\n",
        "    except:\n",
        "        price = \"0\"\n",
        "    try:\n",
        "        address = soup.find(\"h1\", {\"class\": \"ds-address-container\"})\n",
        "    except:\n",
        "        price = \"0\"\n",
        "    try:\n",
        "        year = soup.findAll(\"span\", {\"class\": \"ds-body ds-home-fact-value\"})\n",
        "    except:\n",
        "        price = \"0\"\n",
        "    try:\n",
        "        finalyear = year[1].get_text()\n",
        "    except:\n",
        "        finalyear = \"0000\"\n",
        "    #list for all the data of one house\n",
        "    spechouse = []\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    #Start of address\n",
        "    try:\n",
        "        address = address.get_text()\n",
        "    except:\n",
        "        address = \"N/A\"\n",
        "    print(address)\n",
        "    address = str(address)\n",
        "    finalad = \"\"\n",
        "    for ch in address:\n",
        "        if ch != \",\":\n",
        "            finalad = finalad + ch\n",
        "    #End of address\n",
        "\n",
        "    #price of one house\n",
        "    #start of price of one house code\n",
        "    price = str(price)\n",
        "    price = re.sub('[^0-9]' , '', price)\n",
        "    #spechouse.append(price)\n",
        "    #end of price of one house code\n",
        "    #start of bed, bath, sqft\n",
        "    bed = str(bed)\n",
        "    bedlist = bed.split('>')\n",
        "\n",
        "    templist = []\n",
        "    for item in bedlist:\n",
        "        inlist = []\n",
        "        for st in item:\n",
        "            if st.isdigit():\n",
        "                inlist.append(st)\n",
        "        templist.append(inlist)\n",
        "    templist = ([x for x in templist if x])\n",
        "    count = 0\n",
        "    temper = []\n",
        "    for item in templist:\n",
        "        temper.append(item)\n",
        "        count = count + 1\n",
        "        if(count == 3):\n",
        "            break\n",
        "    foot = \"\"\n",
        "    try:\n",
        "        for num in temper[2]:\n",
        "            foot = foot + num\n",
        "    except:\n",
        "        foot = \"0000\"\n",
        "    try:\n",
        "        spechouse = [houselink, finalad, price, temper[0][0], temper[1][0], foot, finalyear]\n",
        "    except:\n",
        "        spechouse = [\"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\"]\n",
        "    #end of bed, bath, sqft\n",
        "    #f.write(finalad + \",\" + price + \",\" + temper[0][0] + \",\" + temper[1][0] + \",\" + foot + \"\\n\" )\n",
        "    final[i].append(spechouse)\n",
        "    return(spechouse)\n",
        "req_headers = {\n",
        "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
        "    'accept-encoding': 'gzip, deflate, br',\n",
        "    'accept-language': 'en-US,en;q=0.8',\n",
        "    'upgrade-insecure-requests': '1',\n",
        "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'\n",
        "}\n",
        "urllink = []\n",
        "link1 = []\n",
        "urllink.append(\"https://www.zillow.com/mount-pleasant-sc/luxury-homes//homes/for_sale/house,condo,apartment_duplex,mobile,townhouse_type/priced_sort/0_mmm/16_p/\")\n",
        "for link in urllink:\n",
        "    with requests.Session() as s:\n",
        "        url = link\n",
        "        r = s.get(url, headers=req_headers)\n",
        "    soup = BeautifulSoup(r.content, 'lxml')\n",
        "    content = soup.findAll(\"a\",{\"class\":\"list-card-img\"})\n",
        "    content = str(content) \n",
        "    quotation = content.split('\"')\n",
        "    count = 0\n",
        "    for item in quotation:  \n",
        "        if (item.find(\"https://www.zillow.com/homedetail\") != -1):\n",
        "            link1.append(item)\n",
        "#making the file start\n",
        "filename = \"housing16page.csv\"\n",
        "f = open(filename, \"w\")\n",
        "headers = \"link, Address, Price, #Bed, #Bath, Square Foot, Year Built, date1, price1, date2, price2, date3, price3, date4, price4, date5, price5, date6, price6\\n\"\n",
        "f.write(headers)\n",
        "#end of making the file\n",
        "final = []\n",
        "for item in link1:\n",
        "    final.append([])\n",
        "#end of basics function\n",
        "#puts each sublist into the final list\n",
        "finallist = []\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "options.add_experimental_option('useAutomationExtension', False)\n",
        "options.add_argument('--ignore-certificate-errors')\n",
        "options.add_argument('--incognito')\n",
        "#options.add_argument('--headless')\n",
        "DRIVER_PATH = '/Users/ryuno/Downloads/chromedriver'\n",
        "browser = webdriver.Chrome(options=options,executable_path=DRIVER_PATH)\n",
        "for i in range(len(link1)):\n",
        "    #finallist.append(basics(item)) #the argument in basics should be replaced with item\n",
        "    basics(link1[i], i)\n",
        "    browser.get(link1[i])\n",
        "    time.sleep(6)\n",
        "    html = browser.page_source\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    #start of cleaning up price history code\n",
        "    table = soup.find(\"table\", {\"class\": \"oj51b6-2 hxGMPN\"})\n",
        "    try:\n",
        "        pricehist = table.get_text()\n",
        "    except:\n",
        "        pricehist = \"0\"\n",
        "    pricehist = str(pricehist)\n",
        "    rec(pricehist, i)\n",
        "    print(pricehist)\n",
        "for i in range(len(final)):\n",
        "    biglist = []\n",
        "    for j in range(len(final[i])):\n",
        "        for k in range(len(final[i][j])):\n",
        "            biglist.append(final[i][j][k])\n",
        "    for x in range(len(biglist)):\n",
        "        f.write(biglist[x] + \",\")\n",
        "    f.write(\"\\n\")\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}